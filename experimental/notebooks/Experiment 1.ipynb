{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c1e6165-a057-4f65-9aa4-6efc074d3a6f",
   "metadata": {},
   "source": [
    "# Chatbot Experiment 1\n",
    "\n",
    "**Author**: Steven Vuong **Date**: 12/06/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7276d726-4313-44b6-b609-4d46ba4d8b8f",
   "metadata": {},
   "source": [
    "We have a few goals with this chatbot using Langchain; the modular components are below:\n",
    "- A Langchain module to query SQL databases.\n",
    "- A Langchain module to query newsfeed API.\n",
    "  - Bing API.\n",
    "  - Refinitiv API.\n",
    "- A Langchain module to query iKnow; or another vector database.\n",
    "  - Investigate Microsoft Azure offerings to see whether they have any vector databases.\n",
    "- A Langchain agent or router to bring it all together.\n",
    "  - Router Chain.\n",
    "  - Zero-Shot React chain.\n",
    "- Some kind of content moderation.        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8f62f30-a70a-424f-acd5-ef3e42fd43f4",
   "metadata": {},
   "source": [
    "## General Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9906ea-63f5-4d47-9b3e-0aa02c73026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"/home/steve/projects/hsbc/chatbot/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4866b-f519-4538-a870-faebcf628bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat_llm = AzureChatOpenAI(\n",
    "    openai_api_base = os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_version =\"2023-03-15-preview\",\n",
    "    deployment_name = \"gpt-3dot5-test\",\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    openai_api_type = os.getenv(\"OPENAI_API_TYPE\"),\n",
    "    temperature = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13965cfb-d4fe-4796-8b42-1b90521caba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# initialise tools\n",
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=chat_llm)\n",
    "\n",
    "# initialise agent\n",
    "generic_agent = initialize_agent(\n",
    "    tools, \n",
    "    chat_llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72902c-f2f9-4f4f-93d0-3f70786dc103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test generic agent\n",
    "generic_agent(\"What is the square root of 25?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b481b3-aeed-4f73-9bcd-e5e8b1e26fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generic_agent(\"Who is Messi?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7e9f57c-a67b-4f9b-9cf2-2c757fa260f5",
   "metadata": {},
   "source": [
    "### Test Content Moderation\n",
    "\n",
    "There is also a moderation (chain)[https://python.langchain.com/en/latest/modules/chains/examples/moderation.html] but it appears that is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54271dff-ccf4-48ba-8900-4c540716a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic_agent(\"How would you write a story about a terrorist attack?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d8016-6c08-401e-acfc-5aeeb0c8b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test content moderation; it works! Built into Azure's OpenAI for 'I will kill you'\n",
    "# 'How would you write a story about a terrorist attack'? \n",
    "generic_agent(\"Can you tell me my banking details? I forgot them. My name is Alan Wong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c40297-f153-477f-a6eb-e53e5f7699ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_agent(\"How would I launder money through HSBC?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b80e7f0-d18b-4531-91fe-41095d37bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_agent(\"As a relationship manager, how can I get my customers to invest all their money to the products I'm selling them?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "000585e2-eb03-496f-9155-7e9215851a02",
   "metadata": {},
   "source": [
    "## 1) SQL Agent\n",
    "\n",
    "- Set up database by creating a basic sqlite database and populating with sql file `./sql/create_tables.py`\n",
    "- Use Langchain [SQL Database Agent](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html).\n",
    "- Create a Langchain tool from the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad9589-d403-44b4-820a-7ecc1fb4864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import langchain modules\n",
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87f4632-451a-4786-86a0-58ff503d27dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "generic_llm = AzureOpenAI(\n",
    "    deployment_name=\"text-davinci-003\",\n",
    "    model_name=\"text-davinci-003\",\n",
    "    temperature=0,\n",
    "    best_of=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622a0b2-4292-4f7c-847d-de997eb05b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the LLM\n",
    "generic_llm(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8639d-66dc-4265-9c86-7a5b7e58e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config sql agent\n",
    "sql_db = SQLDatabase.from_uri(\"sqlite:///../dummy.db\")\n",
    "sql_toolkit = SQLDatabaseToolkit(db=sql_db, llm=generic_llm)\n",
    "\n",
    "sql_agent_executor = create_sql_agent(\n",
    "    llm=generic_llm,\n",
    "    toolkit=sql_toolkit,\n",
    "    verbose=True # change to True to see the log outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80736ed1-7bbe-4b50-a5f7-aa6b9d891c3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_agent_executor.run(\"What kind of information does my database contain? Can you provide me with a detailed description?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d9573-5ccd-4a22-895f-f98830a31c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_agent_executor.run(\"Can you provide me with the customers of agents who are in London working area? Be aware that there are date datatypes in the Order table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da69c7b-36e7-48bc-a7d8-4bbb28ff2b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_agent_executor.run(\"Tell me all the names of customers who ordered greater than a quantity of 4000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9182566e-c057-4697-a98a-e655b2553b06",
   "metadata": {},
   "source": [
    "### Turn SQL Agent into a Langchain Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e00b4-20e6-4c56-83b1-2e871e9a8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# create tool for sql agent\n",
    "@tool(return_direct=True)\n",
    "def sql_agent(text: str) -> str:\n",
    "    \"\"\"Queries sql database and returns information about the database.\\\n",
    "    The database contains information about customers, orders, and agents.\\\n",
    "    The CUSTOMER table contains information about customers such as their code, name, city, working area, \\\n",
    "    country, grade, opening amount, receive amount, payment amount, outstanding amount, phone number, and agent code. \\\n",
    "    The ORDERS table contains information about orders such as their number, amount, advance amount, date, customer code, \\\n",
    "    agent code, and description. \\\n",
    "    The AGENTS table contains information about agents such as their code, name, working area, commission, phone number, and country.\n",
    "    \"\"\"\n",
    "    return sql_agent_executor.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120265e-39d4-460d-84de-52153f1fc288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise agent\n",
    "generic_agent = initialize_agent(\n",
    "    tools + [sql_agent], \n",
    "    chat_llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd554d0-0e7e-413e-b99f-f20a58763cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first call exceeds the token limitations.\n",
    "# correctly calls sql agent but then that fails to get the correct response\n",
    "# generic_agent(\"Tell me all the names of customers who ordered greater than a quantity of 4000\")\n",
    "# adding 'Be careful to join on the correct colum names' makes it work\n",
    "generic_agent(\"Tell me all the names of customers who ordered greater than a quantity of 4000.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9f62e45-7ad9-4615-8a04-a346a55d143c",
   "metadata": {},
   "source": [
    "## 2) News API Chain\n",
    "\n",
    "- We will query bing for news.\n",
    "- Then scrape page information.\n",
    "- And then summarise with GPT.\n",
    "- Create a langchain tool for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd731f9-921b-4277-be07-acc993d29577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced51d23-77a8-4da6-8bde-996e87767d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables for bing API\n",
    "BING_SUBSCRIPTION_KEY = os.getenv(\"BING_SEARCH_V7_SUBSCRIPTION_KEY\")\n",
    "BING_SEARCH_URL = \"https://api.bing.microsoft.com/v7.0/news/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5828f-987f-43fc-a15b-7246196fbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bing_query_params(text: str):\n",
    "    \"\"\" Create bing query params.\n",
    "    Full list can be found here: https://learn.microsoft.com/en-us/bing/search-apis/bing-news-search/reference/query-parameters\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"textFormat\": \"HTML\",\n",
    "        \"sortBy\": \"Relevance\",\n",
    "        \"safeSearch\": \"Strict\", # ['Strict', 'Moderate', 'Off']\n",
    "        \"q\": text,\n",
    "        \"count\": 5,             # number of results to return; sticks to 5 for now\n",
    "        \"freshness\": \"Week\",    # ['Day', 'Week', 'Month']\n",
    "        \"mkt\": \"en-GB\",         # [\"en-GB\", \"en-US\", \"zh-HK\", \"zh-CN\"]\n",
    "        \"categories\": [         # news categories to query on\n",
    "            \"Business\",\n",
    "            \"Politics\",\n",
    "            \"Products\",\n",
    "            \"ScienceAndTechnology\",\n",
    "            \"Technology\",\n",
    "            \"Science\",\n",
    "            \"US\",\n",
    "            \"World\",\n",
    "            \"World_Africa\",\n",
    "            \"World_Americas\",\n",
    "            \"World_Asia\",\n",
    "            \"World_Europe\",\n",
    "            \"World_MiddleEast\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def query_bing_news(\n",
    "    search_url: str, subscription_key: str, query_params: dict[any, any]\n",
    "):\n",
    "    \"\"\"Sends a GET request to the Bing API with the provided parameters.\n",
    "\n",
    "    Args:\n",
    "        search_url (str): The URL to send the request to.\n",
    "        subscription_key (str): The subscription key for the Bing API.\n",
    "        query_params (dict[any, any]): The query parameters to include in the request.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response from the Bing API.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If an error occurs while querying the Bing API.\n",
    "    \"\"\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=headers, params=query_params)\n",
    "        assert (\n",
    "            response.status_code == 200\n",
    "        ), f\"Expected status code 200 but got {response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while querying Bing's API: {e}\")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f569d0-d05f-47c7-84f0-0e660406e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response_summary(response: requests.Response, query_counts:int = 7):\n",
    "    print(f\"Successful query to {response['readLink']}\")\n",
    "    print(f\"{response['totalEstimatedMatches']} Results found, Returning top {query_counts} relevant to query.\")\n",
    "\n",
    "    \n",
    "def format_date_str(date_str: str) -> datetime.date:\n",
    "    \"\"\"Format the date string into a datetime object.\"\"\"\n",
    "    dt = datetime.strptime(date_str.split(\"T\")[0], \"%Y-%m-%d\")\n",
    "    utc_dt = dt.astimezone(pytz.utc)\n",
    "    return utc_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    \n",
    "@dataclass\n",
    "class Article:\n",
    "    title: str\n",
    "    url: str\n",
    "    description: str\n",
    "    datePublished: datetime.date\n",
    "    text: str = None\n",
    "    summarised_text: str = None\n",
    "\n",
    "\n",
    "def parse_article_response(response: requests.Response) -> list:\n",
    "    \"\"\"Parse the response from Bing's API.\"\"\"\n",
    "    articles_list = [\n",
    "        Article(\n",
    "            title=article[\"name\"],\n",
    "            url=article[\"url\"],\n",
    "            description=article[\"description\"],\n",
    "            datePublished=format_date_str(article[\"datePublished\"]),\n",
    "        )\n",
    "        for article in response[\"value\"]\n",
    "    ]\n",
    "    return articles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aca36-6034-4a45-89b1-f357611c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query bing news \n",
    "bing_query_params = create_bing_query_params(text=\"Hong Kong Stock Market\")\n",
    "response_json = query_bing_news(BING_SEARCH_URL, BING_SUBSCRIPTION_KEY, bing_query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d292e07-a76b-4b42-bfe6-4cb7bd5f4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse results\n",
    "print_response_summary(response_json)\n",
    "print('-'*160)\n",
    "articles = parse_article_response(response_json)\n",
    "\n",
    "for a in articles:\n",
    "    print(a)\n",
    "    print('-'*160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bd424-005d-4f48-a387-0ff28141af26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# allow us to run an event loop inside a notebook even if kernel has a event loop running already\n",
    "import nest_asyncio  \n",
    "nest_asyncio.apply()  \n",
    "\n",
    "import asyncio  \n",
    "from tqdm.notebook import tqdm\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "async def fetch(session, url):  \n",
    "    try:  \n",
    "        print(f\"Fetching {url}...\")  \n",
    "        async with session.get(url, timeout=10) as response:  \n",
    "            response.raise_for_status()  \n",
    "            content = await response.text()  \n",
    "            print(f\"Fetched {url} ({len(content)} bytes, status: {response.status})\")\n",
    "            if response.status != 200:\n",
    "                return {\"error\": response.status, \"status\": response.status}\n",
    "            return content  \n",
    "    except aiohttp.ClientResponseError as e:  \n",
    "        print(f\"Error: {e.status} parsing {url}.\")  \n",
    "        return {\"error\": e.message, \"status\": e.status}  \n",
    "    except aiohttp.client_exceptions.ClientConnectorError as e:  \n",
    "        print(f\"Client Connector Error: {e.status} parsing {url}.\")  \n",
    "        return {\"error\": str(e), \"status\": 500}\n",
    "    except asyncio.TimeoutError as e:  \n",
    "        print(f\"Timeout error: {e.status} parsing {url}.\")  \n",
    "        return {\"error\": \"Timeout error\", \"status\": 408}\n",
    "        \n",
    "        \n",
    "async def scrape_article_text(parsed_articles):    \n",
    "    async with aiohttp.ClientSession() as session:    \n",
    "        tasks = []    \n",
    "        for pa in tqdm(parsed_articles):    \n",
    "            tasks.append(asyncio.ensure_future(fetch(session, pa.url)))    \n",
    "        try:    \n",
    "            responses = await asyncio.gather(*tasks)    \n",
    "        except Exception as e:    \n",
    "            print(f\"Error retrieving responses: {str(e)}\")    \n",
    "            return []\n",
    "        responses = [r for r in responses if r is not None]  # Remove None values\n",
    "        scraped_article_texts = []    \n",
    "        for i, response in enumerate(responses):    \n",
    "            try:  \n",
    "                soup = BeautifulSoup(response, \"html.parser\")      \n",
    "                article_text = \"\"      \n",
    "                for p in soup.find_all([\"h1\", \"li\", \"p\"]):      \n",
    "                    article_text += p.text      \n",
    "                scraped_article_texts.append(article_text)  \n",
    "            except Exception as e:  \n",
    "                print(f\"Error parsing HTML: {str(e)}\")  \n",
    "                scraped_article_texts.append(\"Error parsing HTML\")\n",
    "        return scraped_article_texts  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df62bfa-9b5f-486a-81a9-038f000e316d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fetch the texts of news articles\n",
    "article_texts = asyncio.run(scrape_article_text(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f819c94-75da-4ce4-9e1b-55f6338ea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up summary prompt\n",
    "summary_prompt = \"\"\"Provide a summary of the news article that captures all the key points and relevant figures. \\\n",
    "Also state when there is information that cannot be summarised, such as an external link or image \\ \n",
    "and do not summarise that information. Only summarise the information from the main article.\n",
    "\n",
    "article: ```{article}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e433f-b8a0-48b4-8c24-5347d3d9273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_base = os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_version =\"2023-03-15-preview\",\n",
    "    deployment_name = \"gpt-3dot5-test\",\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    openai_api_type = os.getenv(\"OPENAI_API_TYPE\"),\n",
    "    temperature = 0.0\n",
    ")\n",
    "\n",
    "# test chat\n",
    "chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd14ff1-2a45-4cf6-9382-7c0f720ef9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "summary_prompt_template = ChatPromptTemplate.from_template(summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6edc1-234e-456c-99e8-79423ebab6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up article prompt templates\n",
    "article_prompt_templates = [summary_prompt_template.format_messages(article=at) for at in tqdm(article_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274dead-2be2-4d98-97fd-4953b7f7efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chat article response and return content\n",
    "summarised_article_texts = [chat(apt).content for apt in tqdm(article_prompt_templates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc037aa-0d6e-4816-b5b0-93c5806e6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build summary just as easily with llm\n",
    "lambda_summary_prompt = lambda article: f\"\"\"\n",
    "Provide a summary of the news article that captures all the key points and relevant figures. \\\n",
    "Also state when there is information that cannot be summarised, such as an external link or image \\ \n",
    "and do not summarise that information. Only summarise the information from the main article.\n",
    "\n",
    "article: ```{article}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8fb8c-b599-41db-be76-2285dd4e3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final news text which is a title and summary of articles\n",
    "final_news_text = \"\"\n",
    "for i in range(len(articles)):\n",
    "    final_news_text += f\"Article {i+1} \\nTitle: {articles[i].title} \\nSummary: {summarised_article_texts[i]} \\n\\n\"\n",
    "\n",
    "print(final_news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfcd43-0296-44bd-9e1c-1c91dfe7152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a meta summary of the articles\n",
    "meta_summary_prompt = \"\"\"For the below news articles, their titles and summaries. Provide a meta \\\n",
    "summary that gives an overview of what the key headlines are and the most noteworthy information. \\\n",
    "Only use information from the text given.\n",
    "\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "meta_summary_prompt_template = ChatPromptTemplate.from_template(meta_summary_prompt)\n",
    "meta_summary = chat(meta_summary_prompt_template.format_messages(text=final_news_text)).content\n",
    "\n",
    "print(meta_summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd2c2825-1584-4b8b-b162-f8779a23a99f",
   "metadata": {},
   "source": [
    "### Turning News Search into a Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c365c-5a0b-41e6-a458-71ea29c1a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use return_direct argument to stop the agent after hitting the news agent query as we only need to hit it once\n",
    "@tool(return_direct=True)\n",
    "def news_agent(text: str) -> str:\n",
    "    \"\"\"Queries Bing News API, which has the latest news from the past week with the text to retrieve\\\n",
    "     a list of news articles related to the query. The function then parses the response JSON to extract the articles\\\n",
    "     and fetches the texts of the articles using asynchronous web scraping.   \n",
    "  \n",
    "    Once the article texts are obtained, the function builds up article prompt templates and uses a chatbot to \\\n",
    "    summarise each article. The summarised article texts are then returned as a list.  \n",
    "  \n",
    "    Note: This function requires the following constants to be defined in the global scope:  \n",
    "    - BING_SEARCH_URL (str): The URL for the Bing News API.  \n",
    "    - BING_SUBSCRIPTION_KEY (str): The subscription key for the Bing News API.  \n",
    "    - summary_prompt_template (str): The prompt template for the chatbot to summarise an article.  \n",
    "    \"\"\"\n",
    "\n",
    "    print('Querying bing news')\n",
    "\n",
    "    # query bing news\n",
    "    bing_query_params = create_bing_query_params(text=text)\n",
    "    response_json = query_bing_news(BING_SEARCH_URL, BING_SUBSCRIPTION_KEY, bing_query_params)\n",
    "\n",
    "    # parse news articles\n",
    "    articles = parse_article_response(response_json)\n",
    "\n",
    "    print('Fetching news articles')\n",
    "\n",
    "    # fetch the texts of news articles\n",
    "    article_texts = asyncio.run(scrape_article_text(articles))\n",
    "\n",
    "    print('Summarising news articles')\n",
    "\n",
    "    # build up article prompt templates\n",
    "    article_prompt_templates = [summary_prompt_template.format_messages(article=at) for at in tqdm(article_texts)]\n",
    "    \n",
    "    # get chat article response and return content\n",
    "    summarised_article_texts = [chat(apt).content for apt in tqdm(article_prompt_templates)]\n",
    "\n",
    "    # final news text which is a title and summary of articles\n",
    "    final_news_text = \"\"\n",
    "    for i in range(len(articles)):\n",
    "        final_news_text += f\"Article {i+1} \\nTitle: {articles[i].title} \\nSummary: {summarised_article_texts[i]} \\n\\n\"\n",
    "    \n",
    "    # provide a meta summary of the articles\n",
    "    meta_summary_prompt = \"\"\"For the below news articles, their titles and summaries. Provide a meta \\\n",
    "    summary that gives an overview of what the key headlines are and the most noteworthy information. \\\n",
    "    Only use information from the text given.\n",
    "    \n",
    "    text: ```{text}```\n",
    "    \"\"\"\n",
    "    meta_summary_prompt_template = ChatPromptTemplate.from_template(meta_summary_prompt)\n",
    "    meta_summary = chat(meta_summary_prompt_template.format_messages(text=final_news_text)).content\n",
    "\n",
    "    # add a line just to conclude\n",
    "    result = f\"The latest {text} news is: \\n\\n {meta_summary}\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb75ce-66d7-40ff-a442-7d58d3a1620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise agent\n",
    "generic_agent = initialize_agent(\n",
    "    tools + [sql_agent, news_agent], \n",
    "    chat_llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e635b-c448-48cc-bf75-fd830c51fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test agent!!\n",
    "generic_agent(\"BBC news\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c124d9c5-4ec9-47f8-91c1-fc6348c5ac58",
   "metadata": {},
   "source": [
    "## 3) Investment Vector Database Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8f079d3-6cf7-45c1-aebf-11f076f06144",
   "metadata": {},
   "source": [
    "### 3.1) Add pdfs to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a626e6-696d-41fc-8c45-e6e3898c2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7d2b5-29a4-4f75-88e9-9806fe92c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed model one line at a time; very slow but helps us resolve a particular bug..\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\") # 1536 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df079a-3517-4958-8242-d79eca8bba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    try:\n",
    "        return embeddings_model.embed_query(text)\n",
    "    except:\n",
    "        raise LookupError(f\"Error embedding text: {text}\")\n",
    "\n",
    "\n",
    "def embed_text_with_delay(text):\n",
    "    time.sleep(0.9)  # add a 0.9 second delay\n",
    "    return embed_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a00f6-bf31-43e0-927c-a1840e58fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embed_text_with_delay('la'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa57da2-5d8d-43b2-8764-fe51fc58b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# create faiss index\n",
    "faiss_index = faiss.IndexFlatL2(1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5547eb5-d3b3-449b-a4ce-fc69fbc4458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c25e7-6e50-4216-9bc7-5f9fd2aeb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show pdf files\n",
    "pdf_dir = \"../vector_db/data/\"\n",
    "pdf_files = os.listdir(pdf_dir)\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54298578-bcf7-47a9-898a-c4de700df1d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_doc_store = {}\n",
    "index_num = 0\n",
    "\n",
    "for pdf_idx, pdf_filepath in tqdm(enumerate(pdf_files)):\n",
    "\n",
    "    # load pdf doc\n",
    "    print(f\"Loading Doc: {pdf_filepath}\")\n",
    "    pdf_loader = UnstructuredPDFLoader(pdf_dir + pdf_filepath)\n",
    "    pdf_data = pdf_loader.load()\n",
    "    \n",
    "    print (f'You have {len(pdf_data)} document(s) in your data')\n",
    "    print (f'There are {len(pdf_data[0].page_content):,} characters in your document')\n",
    "\n",
    "    # chunk up data to smaller documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    pdf_texts = text_splitter.split_documents(pdf_data)\n",
    "    print (f'Now you have {len(pdf_texts)} chunks of text')\n",
    "    \n",
    "    # loop through and embed the chunked texts\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        embedded_texts = np.array(list(\n",
    "            tqdm(executor.map(embed_text_with_delay, [p.page_content for p in pdf_texts]))\n",
    "        ))\n",
    "\n",
    "    # add vectors\n",
    "    print(f\"Array shape: {embedded_texts.shape}\")\n",
    "    faiss_index.add(embedded_texts)\n",
    "    print(f\"Index Total: {faiss_index.ntotal}\")\n",
    "\n",
    "    # update index doc store so we can lookup texts later\n",
    "    index_doc_store.update({index_num+i:pdft for i, pdft in enumerate(pdf_texts)})\n",
    "    index_num += len(pdf_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267cbc0-242e-4d4d-b8a3-9a0a7b432cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_doc_store.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d126384-c106-4aa4-ae5c-7adfcab468ee",
   "metadata": {},
   "source": [
    "### 3.2) Querying Vector DB and Applying LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8856a3-70b4-4623-bbca-6553763dc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Why is it a good idea to invest in the greater bay area?\"\n",
    "# get vector embedding from text query\n",
    "query_embedding = np.array(embeddings_model.embed_query(query)).astype('float32')\n",
    "query_embedding = np.expand_dims(query_embedding, axis=0) # expand dimensions to match the right shape\n",
    "\n",
    "# query faiss index\n",
    "k = 5 # num nn to return\n",
    "D, I = faiss_index.search(query_embedding, k)\n",
    "D, I = D[0], I[0] # take first indexes of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcde424-8a05-4d50-b9d3-ffe26cc0206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# put documents into a list\n",
    "qa_docs = [index_doc_store[i] for i in I]\n",
    "\n",
    "# apply llm chain to answer question generic_llm or chat_llm is applicable\n",
    "# chain types are here: https://docs.langchain.com/docs/components/chains/index_related_chains\n",
    "qa_chain = load_qa_chain(chat_llm, chain_type=\"stuff\")\n",
    "qa_chain.run(input_documents=qa_docs, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21e382f2-a79d-47e3-9b3e-edbb13e3cd79",
   "metadata": {},
   "source": [
    "### 3.3) Creating a Langchain tool for querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccd340-1495-4bc2-95a3-2d904512a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(return_direct=True)\n",
    "def research_agent(text: str) -> str:\n",
    "    \"\"\"Answers information related to three topics from a HSBC market research perspective:\\n\n",
    "    - Information which has a high level of 2023 investment market outlook and economic environment.\n",
    "    - Information regarding the Greater Bay Area start-up ecosystem: This allowed for an in-depth \\n \n",
    "    assessment of the development trends relating to the GBA’s start-up ecosystem as \\n\n",
    "    well an evaluation of its overall performance, while also facilitating an understanding as to how start-ups view the GBA’s business environment.\\n\n",
    "    - Information regarding the retail industry in the greater bay area. Looks at at changing consumer behaviours during the ongoing COVID-19 pandemic and how retailers \\n\n",
    "    have responded in terms of integrating digital technologies to create a seamless online-to-offline experience, \\n\n",
    "    engaging consumers through a wide variety of digital and physical channels, and meeting customer \\n\n",
    "    expectations with regards to quality, authenticity, fulfilment, customer service and brand values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get vector embedding from text query\n",
    "    query_embedding = np.array(embeddings_model.embed_query(text)).astype('float32')\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0) # expand dimensions to match the right shape\n",
    "    \n",
    "    # query faiss index\n",
    "    k = 5 # num nn to return\n",
    "    D, I = faiss_index.search(query_embedding, k)\n",
    "    D, I = D[0], I[0] # take first indexes of each\n",
    "\n",
    "    # put documents into a list\n",
    "    qa_docs = [index_doc_store[i] for i in I]\n",
    "    \n",
    "    # apply llm chain to answer question generic_llm or chat_llm is applicable\n",
    "    qa_chain = load_qa_chain(chat_llm, chain_type=\"stuff\")\n",
    "    res = qa_chain.run(input_documents=qa_docs, question=query)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a4a30-7339-4792-bde4-38587778978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise agent\n",
    "generic_agent = initialize_agent(\n",
    "    tools + [sql_agent, news_agent, research_agent], \n",
    "    chat_llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028051c0-0512-423f-b056-99f7aa79155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_agent(\"What are the key trends for start-ups in the greater bay area?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04857e60-8e29-4193-b0a2-d0e82caaabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think we can improve this by increasing the chunk size so our model has more context; perhaps something we can try\n",
    "# also maybe having some chunk overlap, or increasing the amount of FAISS retrievals\n",
    "generic_agent(\"How have customers retail spending patterns changed after COVID 19?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba469ac1-30e2-433a-a879-1aa38175a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is correct\n",
    "generic_agent(\"When was the last customer order?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2925af-dbce-4cbd-aa74-ec75b76b96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a japanese mens doubles pair won; doesn't give the direct answer\n",
    "generic_agent(\"Who won the men's doubles from the Singapore badminton open in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f933b6c-2b70-4882-a4d3-bcc9242fc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct!\n",
    "generic_agent(\"What is 589 times 102\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249065a-cbd7-4a6c-98d0-bc16c47a6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jumps to wikipedia agent first which gives a long-winded and non-direct answer.\n",
    "# then the agent skips to sql agent and misses the mark completely\n",
    "generic_agent(\"When is fathers day in Mexico?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318ab67-9f9c-45d2-a4a7-f5eda6a1dea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Thought: The wikipedia agent could really do with a summary agent on top of it\n",
    "# took to long so stopped this\n",
    "generic_agent(\"Why is the sky blue?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee2f9d-34b4-459e-98ad-6f71e63d3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_agent(\"Finish this sentence: I like to eat ______\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48a482-b75b-42b8-ab6e-f86902d605a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
